# Select only storms which made landafall as hurricanes in 2004 and 2005
hu.list0405.1<-subset(hu.1, format.Date(Time, "%Y") %in% c("2004","2005"))
hu.list0405.2<-subset(hu.1, Event=="L" & Status=="HU")
hu.names0405<-intersect(hu.list0405.1$ID,hu.list0405.2$ID)
hu.0405<-subset(hu.1, ID %in% hu.names0405)
hu.0405<-subset(hu.0405,  format.Date(Time, "%H") %in% c("06","18"))
## Add a short time series at the end to extend the final screen
end.data<-data.frame(matrix(0, nrow = 10, ncol = 8))
end.data[,6]<-seq(max(hu.0405$Time), by = "days", length=10)
names(end.data)<-names(hu.0405)
end.data$ID<-"END"
hu.0405<-rbind(hu.0405,end.data)
# Create the animation plot
p3 <-hu.0405 %>%
na.omit() %>%
ggplot() +
borders("world",colour="black",fill="slategray2", resolution=0) +
theme(panel.background = element_rect(fill = 'white'),panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
geom_point(aes(long, lat, frame=Time, colour=MaxWind.mph,size=MaxWind.mph), alpha=0.5) +
geom_path(aes(long, lat,frame=Time, colour=MaxWind.mph,cumulative = TRUE, group=Name)) +
geom_text(aes(x=long, y=lat-2,frame=Time, label=Name)) +
xlab("LONGITUDE") + ylab("LATITUDE") +
scale_color_continuous(low = "green", high = "red",limits=c(0, 200), breaks=seq(0,200, by=50)) +  scale_size_continuous(limits=c(0, 200), breaks=seq(0,200, by=50))  +  guides(color= guide_legend(), size=guide_legend()) +
coord_map(projection = "mercator") +
scale_y_continuous( limits = c( 0 , +50 )) + scale_x_continuous( limits = c( -130 , -5 ))
# gganimate code
p3 + labs(title = 'Time: ') +
transition_time(Date) +
ease_aes('linear')
# Create the animation plot edited to remove frame from aes and use `transition_Manual()`
p3 <-hu.0405 %>%
na.omit() %>%
ggplot() +
borders("world",colour="black",fill="slategray2", resolution=0) +
theme(panel.background = element_rect(fill = 'white'),panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
geom_point(aes(long, lat, colour=MaxWind.mph,size=MaxWind.mph), alpha=0.5) +
geom_path(aes(long, lat, colour=MaxWind.mph,cumulative = TRUE, group=Name)) +
geom_text(aes(x=long, y=lat-2, label=Name)) +
transition_manual(Time)+
xlab("LONGITUDE") + ylab("LATITUDE") +
scale_color_continuous(low = "green", high = "red",limits=c(0, 200), breaks=seq(0,200, by=50)) +  scale_size_continuous(limits=c(0, 200), breaks=seq(0,200, by=50))  +  guides(color= guide_legend(), size=guide_legend()) +
coord_map(projection = "mercator") +
scale_y_continuous( limits = c( 0 , +50 )) + scale_x_continuous( limits = c( -130 , -5 )) +
ease_aes('linear')
# gganimate code
#p3 + labs(title = 'Time: ') +
#  transition_time(Date) +
#  ease_aes('linear')
p3
animate(p3, width = 700, height = 432, fps = 12, rewind = FALSE)
library(tidyverse)
# Read in data set so each line is a character string
AT_file_complete <- read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2021-100522.txt")
PC_file_complete <- read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-nepac-1949-2021-091522.txt")
storm_strings <- read_lines(AT_file_complete)
library(tidyverse)
# Read in data set so each line is a character string
AT_file_complete <- read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2021-100522.txt")
# Read in data set so each line is a character string
AT_file_complete <- readr::read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2021-100522.txt")
# Read in data set so each line is a character string
AT_file_complete <- tidyverse::read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2021-100522.txt")
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
# Read in data set so each line is a character string
AT_file_complete <- tidyverse::read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2021-100522.txt")
PC_file_complete <- read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-nepac-1949-2021-091522.txt")
# Read in data set so each line is a character string
AT_file_complete <- read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2021-100522.txt")
storm_strings <- read_lines(AT_file_complete)
# Identify the header lines that have three commas
header_locations <- str_count(storm_strings, "\\,") == 3
header_locations <- (1:length(storm_strings))[header_locations]
# Extract length of each sub-dataset
headers <- as.list(storm_strings[header_locations])
headers_df <- headers %>%
map(str_sub, start = 1, end = -2) %>% # to remove trailing comma
map(paste0, "\n") %>%                 # to trigger literal read
map_df(read_csv, col_names = c("id", "name", "n_obs"), col_types = "cci") %>%
mutate(name = recode(name, "UNNAMED" = id), skip = header_locations) %>%
select(id, name, skip, n_obs)
column_types <- list(
date = col_character(),
time = col_character(),
record_type = col_character(),
status = col_character(),
lat = col_character(),
long = col_character(),
wind = col_integer(),
pressure = col_integer(),
extent_34_NE = col_integer(),
extent_34_SE = col_integer(),
extent_34_SW = col_integer(),
extent_34_NW = col_integer(),
extent_50_NE = col_integer(),
extent_50_SE = col_integer(),
extent_50_SW = col_integer(),
extent_50_NW = col_integer(),
extent_64_NE = col_integer(),
extent_64_SE = col_integer(),
extent_64_SW = col_integer(),
extent_64_NW = col_integer(),
nas = col_integer()
)
column_names <- names(column_types)
#### Parse each storm as its own sub-dataframe
storm_dataframes <- vector("list", nrow(headers_df))
for (i in 1:nrow(headers_df)) {
# get this storm's metadata
row_start = headers_df[i,]$skip + 1
row_end = headers_df[i,]$n_obs + row_start - 1
# subset of rows belonging to this storm
data_subset = storm_strings[row_start:row_end] %>%
paste(collapse = "\n") %>%
paste0("\n")
# read it as a csv
data_subset = read_csv(
data_subset,
col_names = column_names,
col_types = column_types,
na = c("", "-99", "-999")
)
problems()
# name and id at the front
data_subset$name = headers_df[i,]$name
data_subset = data_subset %>% relocate(name)
data_subset$id = headers_df[i,]$id
data_subset = data_subset %>% relocate(id)
# add to list of storms
storm_dataframes[[i]] = data_subset
}
# Combine and clean the data sets
library(lubridate)
# combine the storms into one dataframe
storms <- storm_dataframes %>%
bind_rows()
# format the columns
storms <- storms %>%
mutate(
date = ymd(date),
year = year(date),
month = month(date),
day = day(date),
hour = as.numeric(str_sub(time, 1, 2)),
lat_hemisphere = str_sub(lat, -1),
lat_sign = if_else(lat_hemisphere == "N", 1, -1),
lat = as.numeric(str_sub(lat, 1, -2)) * lat_sign,
long_hemisphere = str_sub(long, -1),
long_sign = if_else(long_hemisphere == "E", 1, -1),
long = as.numeric(str_sub(long, 1, -2)) * long_sign,
# wind = wind * 1.15078, # transforms knots to mph,
TSradius1 = extent_34_NE + extent_34_SW,
TSradius2 = extent_34_NW + extent_34_SE,
tropicalstorm_force_diameter = pmax(TSradius1, TSradius2),
HUradius1 = extent_64_NE + extent_64_SW,
HUradius2 = extent_64_NW + extent_64_SE,
hurricane_force_diameter = pmax(HUradius1, HUradius2)
)
# drop rows with missing pressure record
storms <- storms %>%
filter(!is.na(pressure))
# don't abrev.
storms <- storms %>% mutate(
status = factor(recode(status,
"HU" = "hurricane",
"TS" = "tropical storm",
"TD" = "tropical depression",
"EX" = "extratropical",
"SD" = "subtropical depression",
"SS" = "subtropical storm",
"LO" = "other low",
"WV" = "tropical wave",
"DB" = "disturbance"
))
)
# hurricane category
storms <- storms %>%
mutate(category = case_when(
status != "hurricane" ~ NA,
wind >= 137 ~ 5,
wind >= 113 ~ 4,
wind >= 96 ~ 3,
wind >= 83 ~ 2,
wind >= 64 ~ 1,
.default = NA
)) %>%
relocate(category, .after = status)
# drop storms without at least one record that is a tropical depression or higher
storms <- storms %>%
group_by(year, name) %>%
filter(any(status %in% c("hurricane", "tropical storm", "tropical depression"))) %>%
ungroup()
# make names Title casing
storms <- storms %>%
mutate(name = if_else(str_sub(name, 1, 3) %in% c("AL0", "AL1"), name, str_to_title(name)))
# drop a bad data point (add more if found)
storms <- storms %>%
filter( !((year == 1969) & (name == "Debbie") & (long < -350)) )
# simplify
storms <- storms %>%
# drop historical data for simplicity and backwards compatibility
filter(year >= 1975) %>%
# drop some columns
select(name, year, month, day, hour, lat, long, status, category, wind, pressure, tropicalstorm_force_diameter, hurricane_force_diameter)
View(storms)
# hurricane category
storms <- storms %>%
mutate(category = case_when(
(status != "hurricane") ~ NA,
(wind >= 137) ~ 5,
(wind >= 113) ~ 4,
(wind >= 96) ~ 3,
(wind >= 83) ~ 2,
(wind >= 64) ~ 1,
.default = NA
)) %>%
relocate(category, .after = status)
# hurricane category
storms <- storms %>%
mutate(category = case_when(
(status != "hurricane") ~ "NA",
(wind >= 137) ~ 5,
(wind >= 113) ~ 4,
(wind >= 96) ~ 3,
(wind >= 83) ~ 2,
(wind >= 64) ~ 1,
.default = NA
)) %>%
relocate(category, .after = status)
# hurricane category
storms <- storms %>%
mutate(category = case_when(
.status != "hurricane" ~ NA,
.wind >= 137 ~ 5,
.wind >= 113 ~ 4,
.wind >= 96 ~ 3,
.wind >= 83 ~ 2,
.wind >= 64 ~ 1,
.default = NA
)) %>%
relocate(category, .after = status)
# hurricane category
storms <- storms %>%
mutate(category = case_when(
status != "hurricane" ~ NA,
wind >= 137 ~ 5,
wind >= 113 ~ 4,
wind >= 96 ~ 3,
wind >= 83 ~ 2,
wind >= 64 ~ 1,
#.default = NA
TRUE ~ NA
)) %>%
relocate(category, .after = status)
# hurricane category
storms <- storms %>%
mutate(category = case_when(
status != "hurricane" ~ NA,
wind >= 137 ~ 5
,wind >= 113 ~ 4
,wind >= 96 ~ 3
,wind >= 83 ~ 2
,wind >= 64 ~ 1
#.default = NA
,TRUE ~ NA
)) %>%
relocate(category, .after = status)
# simplify
storms <- storms %>%
# drop historical data for simplicity and backwards compatibility
filter(year >= 1975) %>%
# drop some columns
select(name, year, month, day, hour, lat, long, status, wind, pressure, tropicalstorm_force_diameter, hurricane_force_diameter)
write_csv(storms, file="data\NOAA_HURDAT\AThurdat2-1851-2021-100522", colnames=T)
write_csv(storms, file=".data\NOAA_HURDAT\AThurdat2-1851-2021-100522", colnames=T)
write_csv(storms, path=".data\NOAA_HURDAT\", file="AThurdat2-1851-2021-100522", colnames=T)
write_csv(storms, path=".data/NOAA_HURDAT/", file="AThurdat2-1851-2021-100522", colnames=T)
write_csv(storms, path=".data/NOAA_HURDAT/", file="AThurdat2-1851-2021-100522", col_names=T)
write_csv(storms, path="data/NOAA_HURDAT/", file="AThurdat2-1851-2021-100522", col_names=T)
write_csv(storms, path="data/NOAA_HURDAT/AThurdat2-1851-2021-100522", col_names=T)
write_csv(storms, path="data/NOAA_HURDAT/AThurdat2-1851-2021-100522.csv", col_names=T)
write_csv(storms, path="data/NOAA_HURDAT/AT-HURDAT2-1851-2021-100522.csv", col_names=T)
PC_file_complete <- read_file("https://www.nhc.noaa.gov/data/hurdat/hurdat2-nepac-1949-2021-091522.txt")
storm_strings <- read_lines(PC_file_complete)
# Identify the header lines that have three commas
header_locations <- str_count(storm_strings, "\\,") == 3
header_locations <- (1:length(storm_strings))[header_locations]
# Extract length of each sub-dataset
headers <- as.list(storm_strings[header_locations])
headers_df <- headers %>%
map(str_sub, start = 1, end = -2) %>% # to remove trailing comma
map(paste0, "\n") %>%                 # to trigger literal read
map_df(read_csv, col_names = c("id", "name", "n_obs"), col_types = "cci") %>%
mutate(name = recode(name, "UNNAMED" = id), skip = header_locations) %>%
select(id, name, skip, n_obs)
column_types <- list(
date = col_character(),
time = col_character(),
record_type = col_character(),
status = col_character(),
lat = col_character(),
long = col_character(),
wind = col_integer(),
pressure = col_integer(),
extent_34_NE = col_integer(),
extent_34_SE = col_integer(),
extent_34_SW = col_integer(),
extent_34_NW = col_integer(),
extent_50_NE = col_integer(),
extent_50_SE = col_integer(),
extent_50_SW = col_integer(),
extent_50_NW = col_integer(),
extent_64_NE = col_integer(),
extent_64_SE = col_integer(),
extent_64_SW = col_integer(),
extent_64_NW = col_integer(),
nas = col_integer()
)
column_names <- names(column_types)
#### Parse each storm as its own sub-dataframe
storm_dataframes <- vector("list", nrow(headers_df))
for (i in 1:nrow(headers_df)) {
# get this storm's metadata
row_start = headers_df[i,]$skip + 1
row_end = headers_df[i,]$n_obs + row_start - 1
# subset of rows belonging to this storm
data_subset = storm_strings[row_start:row_end] %>%
paste(collapse = "\n") %>%
paste0("\n")
# read it as a csv
data_subset = read_csv(
data_subset,
col_names = column_names,
col_types = column_types,
na = c("", "-99", "-999")
)
problems()
# name and id at the front
data_subset$name = headers_df[i,]$name
data_subset = data_subset %>% relocate(name)
data_subset$id = headers_df[i,]$id
data_subset = data_subset %>% relocate(id)
# add to list of storms
storm_dataframes[[i]] = data_subset
}
# Combine and clean the data sets
library(lubridate)
# combine the storms into one dataframe
storms <- storm_dataframes %>%
bind_rows()
#####################
# format and cleanup
# format the columns
storms <- storms %>%
mutate(
date = ymd(date),
year = year(date),
month = month(date),
day = day(date),
hour = as.numeric(str_sub(time, 1, 2)),
lat_hemisphere = str_sub(lat, -1),
lat_sign = if_else(lat_hemisphere == "N", 1, -1),
lat = as.numeric(str_sub(lat, 1, -2)) * lat_sign,
long_hemisphere = str_sub(long, -1),
long_sign = if_else(long_hemisphere == "E", 1, -1),
long = as.numeric(str_sub(long, 1, -2)) * long_sign,
# wind = wind * 1.15078, # transforms knots to mph,
TSradius1 = extent_34_NE + extent_34_SW,
TSradius2 = extent_34_NW + extent_34_SE,
tropicalstorm_force_diameter = pmax(TSradius1, TSradius2),
HUradius1 = extent_64_NE + extent_64_SW,
HUradius2 = extent_64_NW + extent_64_SE,
hurricane_force_diameter = pmax(HUradius1, HUradius2)
)
# drop rows with missing pressure record
storms <- storms %>%
filter(!is.na(pressure))
# don't abrev.
storms <- storms %>% mutate(
status = factor(recode(status,
"HU" = "hurricane",
"TS" = "tropical storm",
"TD" = "tropical depression",
"EX" = "extratropical",
"SD" = "subtropical depression",
"SS" = "subtropical storm",
"LO" = "other low",
"WV" = "tropical wave",
"DB" = "disturbance"
))
)
# hurricane category
#storms <- storms %>%
#  mutate(category = case_when(
#   status != "hurricane" ~ NA,
#    wind >= 137 ~ 5,
#    wind >= 113 ~ 4,
#    wind >= 96 ~ 3,
#    wind >= 83 ~ 2,
#    wind >= 64 ~ 1,
#   .default = NA
#  )) %>%
#  relocate(category, .after = status)
# drop storms without at least one record that is a tropical depression or higher
storms <- storms %>%
group_by(year, name) %>%
filter(any(status %in% c("hurricane", "tropical storm", "tropical depression"))) %>%
ungroup()
# drop all rows that are not at least a depression
# might want to use this filter if the file size is an issue
# storms <- storms %>% filter(status %in% c("hurricane", "tropical storm", "tropical depression"))
# make names Title casing
storms <- storms %>%
mutate(name = if_else(str_sub(name, 1, 3) %in% c("AL0", "AL1"), name, str_to_title(name)))
# drop a bad data point (add more if found)
storms <- storms %>%
filter( !((year == 1969) & (name == "Debbie") & (long < -350)) )
# simplify
storms <- storms %>%
# drop historical data for simplicity and backwards compatibility
filter(year >= 1975) %>%
# drop some columns
select(name, year, month, day, hour, lat, long, status, wind, pressure, tropicalstorm_force_diameter, hurricane_force_diameter)
write_csv(storms, path="data/NOAA_HURDAT/PC-HURDAT2-1851-2021-100522.csv", col_names=T)
# Upload packages
library(ggplot2)
library(maps)
library(ggthemes)
library(gganimate)
library(dplyr)
# Load input data
data1<-read.csv('./data/NOAA_HURDAT/PC-HURDAT2-1851-2021-100522.csv')
# Load input data
data1<-read.csv('./data/NOAA_HURDAT/PC-HURDAT2-1851-2021-100522.csv') %>%
mutate(Latitude = as.character(Latitude))
View(data1)
# Format the coordinates
dat<-as.character(data1$Latitude)
new<-substr(dat,1,nchar(dat)-1)
lat<-as.numeric(new)
dat<-as.character(data1$Longitude)
new<-substr(dat,1,nchar(dat)-1)
long<-as.numeric(new)
long<- -abs(long)
coord<-as.data.frame(long)
coord<-cbind(coord, lat)
out<-subset(coord, long < -100) ##Find the outliers
total<-cbind(data1, coord)
outRM<-total[-c(22985,22986),]  ##Remove the outliers
hu<-outRM
# Create a time column
hu$Date<-as.character(hu$Date)
hu$Time[hu$Time>0]<-hu$Time[hu$Time>0]/100
hu$Date<-as.Date(hu$Date,'%Y%m%d')
hu$Time<-ISOdatetime(hu$Date, hu$Time,0,0, 0, 0)
# Some data manipulation
hu$MaxWind.mph<-hu$Maximum.Wind*1.150779 # Convert wind speed from knot to miles per hour
hu$Name<-trimws(as.character(hu$Name))
# Select columns of interest
hu.1<-as.data.frame(hu[c("ID","Name","lat","long","MaxWind.mph", "Time","Date","Event", "Status")])
hu.1$Event<-trimws(as.character(hu.1$Event))
hu.1$Status<-trimws(as.character(hu.1$Status))
# Select only storms which made landafall as hurricanes in 2004 and 2005
hu.list0405.1<-subset(hu.1, format.Date(Time, "%Y") %in% c("2004","2005"))
# Load input data
data1<-read.csv('./data/NOAA_HURDAT/PC-HURDAT2-1851-2021-100522.csv')
# Format the coordinates
dat<-as.character(data1$Latitude)
new<-substr(dat,1,nchar(dat)-1)
lat<-as.numeric(new)
dat<-as.character(data1$Longitude)
new<-substr(dat,1,nchar(dat)-1)
long<-as.numeric(new)
long<- -abs(long)
coord<-as.data.frame(long)
coord<-cbind(coord, lat)
out<-subset(coord, long < -100) ##Find the outliers
total<-cbind(data1, coord)
outRM<-total[-c(22985,22986),]  ##Remove the outliers
hu<-outRM
# Create a time column
hu$Date<-as.character(hu$Date)
hu$Time[hu$Time>0]<-hu$Time[hu$Time>0]/100
hu$Date<-as.Date(hu$Date,'%Y%m%d')
hu$Time<-ISOdatetime(hu$Date, hu$Time,0,0, 0, 0)
# Some data manipulation
hu$MaxWind.mph<-hu$Maximum.Wind*1.150779 # Convert wind speed from knot to miles per hour
hu$Name<-trimws(as.character(hu$Name))
data1<-read.csv('./data/NOAA_HURDAT/AT-HURDAT2-1851-2021-100522.csv')
# Format the coordinates
dat<-as.character(data1$Latitude)
new<-substr(dat,1,nchar(dat)-1)
lat<-as.numeric(new)
dat<-as.character(data1$Longitude)
new<-substr(dat,1,nchar(dat)-1)
long<-as.numeric(new)
long<- -abs(long)
coord<-as.data.frame(long)
coord<-cbind(coord, lat)
out<-subset(coord, long < -100) ##Find the outliers
total<-cbind(data1, coord)
outRM<-total[-c(22985,22986),]  ##Remove the outliers
hu<-outRM
# Create a time column
hu$Date<-as.character(hu$Date)
hu$Time[hu$Time>0]<-hu$Time[hu$Time>0]/100
hu$Date<-as.Date(hu$Date,'%Y%m%d')
hu$Time<-ISOdatetime(hu$Date, hu$Time,0,0, 0, 0)
# Some data manipulation
hu$MaxWind.mph<-hu$Maximum.Wind*1.150779 # Convert wind speed from knot to miles per hour
hu$Name<-trimws(as.character(hu$Name))
